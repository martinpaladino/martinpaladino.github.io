---
title: "Modelo logit con R"
author: "Martín Paladino"
date: "5 de abril de 2017"
output:
  html_document:
    highlight: textmate
    number_sections: yes
    theme: journal
    toc: yes
---

```{r, include=F}
knitr::opts_chunk$set(echo = TRUE, warning= FALSE, message = FALSE, fig.width = 8, fig.height = 8)
library(tidyverse)
library(magrittr)
library(pander)
library(knitr)
library(forcats)
#Función para imprimir las categorías de referencia: y o x =0. 

ref <- function(.){print(summarise_if(., is.factor, funs(levels(.)[1])))}

```

    
#Introducción.
Los [modelos lineales](martinpaladino.github.io/modelos_lineales_con_R.html) nos permiten predecir el valor de una variable a partir del valor de otra u otras. En su formulación original se desarrollaron para variables dependientes continuas, es decir, para estimar los valores que toma y para cada valor de x a partir de una ordenada al origen y una o más pendientes. Sin embargo puede ser de interés tomar como variables dependiente a una categórica y eso es lo que hacen los modelos logit, también conocidos como regresión logística. Claro que no es muy útil predecir cualquier valor de $y$ dadas $x_1$, $x_2$, $x_n$, dado que $y_{categórica}$ solamente puede adquirir dos valores, 0 y 1. Lo que buscaremos predecir son las probabilidades de 0 o 1. Es decir, dado cierto valor de $x$ ¿cuál es la probabilidad de $y_0$ y de $y_1$? 
Podríamos simplificarnos la tarea y ajustar sin modificaciones un modelo lineal con la forma de la ecuación 1. 

(@lineal_simple) $y=\beta_0+\beta_1x+...\beta_ix$

Le pediríamos al modelo que predijera 0 o 1, al fin y al los podríamos considerar valores numéricos e interpretar adecuadamente. Sin embargo estaríamos violando los supuestos de un modelo lineal: la distribución de probabilidad de y categórica no es normal. Sin embargo no todo está perdido. Si y no se ajusta a una distribución normal se puede ajustar a otras distribuciones y, para y dicotómica, podemos asumir que se ajusta a una distribución binomial. En ese caso podemos usar la ecuación (@logit)

(@logit) $ln(\frac{p_1}{1-p_1})=\beta_0+\beta_1x+...\beta_ix$

El lado derecho es igual de cualquier modelo lineal, pero el lado izquierdo tiene peculiaridades que vale la pena comentar. Como mencionamos, ya no buscamos al valor de $y$ como una combinación lineal de los valores de $x_1...X_i$. Lo que buscamos es el *logaritmo de las razones de probabilidad de $y=1$*, que obtenemos dividiendo las probabilidades 1 por la probabilidad de 0.^[Como sabemos que la probabilidad de varía entre 0 y 1 entonces 1 menos la probabilidad de de 1 es igual a la probabilidad de 0.] 

>Excurso: El momio tiene razones, que la razón desconoce. 

>Las razones de probabilidad, también llamadas razones de momio o odds ratio, se obtienen dividiendo la probabilidad de éxito por las de fracaso o, más secamente, la probabilidad de 1 entre la probabilidad de 0. Son una transformación de la probabilidad usuales, que varían entre 0 y 1, pero en lugar de eso varían entre 0 e infinito. Una razón de probabilidad 1 significa que ambos eventos tienen la misma probabilidad: la obtuvimos dividiendo 0.5 entre 0.5 Una probabilidad mayor que 1 significa que el evento éxito es más probable que el evento fracaso y menor que uno lo inverso. 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
tribble(~fila,~p0, ~p1,
            1,0.1, 0.9,
            2,0.2, 0.8,
            3,0.3, 0.7, 
            4,0.4, 0.6, 
            5,0.5, 0.5, 
            6,0.6, 0.4, 
            7,0.3, 0.7, 
            8,0.2, 0.8, 
            9,0.1, 0.9) %>% 
  mutate(`RP 1`=p1/p0, `RP 0`=p0/p1) %>% 
  kable(., caption="Razones de probabilidad de algunos pares de probabilidades")
```

>La razón de probabilidad nos da una magnitud de cuanto más probable es un evento que otro. En la cuarta fila de la Tabla 1 encontramos que el evento 1 tiene una razón de probabilidad de 1.5. Esto significa que es un 50% más probable obtener 1 que obtener 0. En la sexta fila la razón de probabilidad de 1 es 0.666: obtener 1 es un 66% menos probable que obtener 0. Profundizaremos estos conceptos más adelante, cuando veamos la interpretación de los coeficientes de un modelo logit. Por ahora aceptemos que las razones de probabilidad son más complicadas de interpretar que las probabilidad a las que estamos acostumbrados, pero no es posible ajustar modelos lineales para variables categóricas de otro modo. C'est comme ça. 

#Ajuste  de modelos logit con `glm()`

Los modelos logit forman parte de lo que conocemos como Modelos Lineales Generalizados. Utilizamos la expresión generalizados porque son un marco general dentro del que caben casos particulares. Los modelos lineales con y continua son un caso particular de los generalizados: aquellos con una distribución normal y una función de enlace directa^[Estimamos directamente el valor y.]. Los modelos logit son un caso particular de los modelos lineales generalizados en los que la distribución es binomial y la función de enlace el logaritmo de las razones de probabilidad, es decir, la función logit que les da nombre. 

La función `glm()` de R nos permite ajustar modelos lineales de muchos tipos, incluyendo los que ajustamos con `lm()`, modelos de Poisson y los logit en los que nos enfocaremos. 
La sintaxis básica para obtener un modelo lineal es `glm(depeendiente~independiente1+independiente2, family="binomial", data=datos")`.

El primer argumento es un objeto de la clase fórmula. A la izquierda del signo  `~` ubicamos a la variable dependiente y a la derecha, unidos por el signo `+` las independientes, si no estamos especificando una interacción entre variables. 

El segundo, `family=binomial()`, especifica la función de probabilidad que utilizaremos. Para modelos logit es una función binomial. Dentro de los paréntesis se puede especificar la función de enlace. Para la familia de distribuciones binomial `glm()` por defecto usa una función logit. Si nos interesa una función probit deberíamos especificar `link=probit`. 

El tercero apunta a un data.frame en el que están los datos. Los nombres de columna del data.frame deben coincidir con las variables especificadas en la fórmula, aunque podría contener más variables que serán descartadas. En el caso de hacer previamente una manipulación de datos encadenada con el operador ` %>%` usamos `.` como sustituto anónimo de los datos. 

##Presentación de los datos.

Introduciremos una nueva base de datos y una hipótesis sustantiva para que nos sirva de guía. La base elaborada por el Sistema de Información Municipal del Instituto Nacional para el Federalismo y el Desarrollo Municipal tiene información sobre los presidentes municipales de México, incluyendo el sexo, partido y título. Como incluye  el número de municipio y entidad federativa podemos combinar esta base de datos con la de CONAPO para agregar más variables. La base de datos tienen algunos problemas que requieren manipulación y que hemos atendido en otra parte(AGREGAR EL ENLACE). Trabajaremos con la base ya limpia, con una N=1881. 
Queremos explorar qué variables explican que un municipio tenga presidente o presidenta municipal. Nuestra primer hipótesis es que el partido político es una buena variable explicativa, considerando que los partidos progresistas son más propensos a apoyar candidaturas femeninas. Sin embargo otras variables podrían intervenir: la ruralidad/urbanidad del municipio, el Grado de Marginación, la región, etc. 


```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(stringr)
#Carga base presidentes municipales ====
presidentes_municipales <- 
  read_csv("./datos/presidentes_municipales.csv", col_types = cols(ap_materno = col_character(), fecha_actualizacion = col_character(), pdo_gob_ini = col_character()))
names(presidentes_municipales)[1] <- "estado"
#Carga base marginación. ====
marginacion <- 
  read_csv("./datos/Base_Indice_de_marginacion_municipal_90-15.csv", col_types = cols(`AÑO` = col_character()), 
    locale = locale(encoding = "UTF-8")) %>%  
      mutate (POB_TOT=gsub(" ","", POB_TOT)) %>%
      mutate(POB_TOT=as.integer(POB_TOT)) %>%
      filter(ENT!="Nacional" & AÑO=="2015")
names(marginacion)[1] <- "CVEMUN" 

#Función para arreglar la base presidentes y unirla con marginación. 
arreglar_y_unir <- function(.) {
  separate(.,integrantes, into=("cabeza_coalicion")) %>%                  
  dplyr::mutate(partido_coalicion=ifelse(is.na(cabeza_coalicion), partido, cabeza_coalicion)) %>%  
    mutate(partido_coalicion=ifelse(partido_coalicion=="CPU", "PAN", partido_coalicion)) %>% 
    mutate (id_estado= ifelse(str_length(id_estado)==1, 
                            paste0("0", id_estado), 
                            id_estado)) %>% 
    mutate(id_municipio= ifelse(str_length(id_municipio)==1, 
                              paste0("00", id_municipio),
                              ifelse(str_length(id_municipio)==2, 
                                     paste0("0", id_municipio), 
                                     id_municipio))) %>% 
    mutate(prof=ifelse(titulo=="C.", "C", "P")) %>% 
  mutate(CVEMUN=paste0(id_estado, id_municipio)) %>% 
  inner_join(., marginacion) %>% 
  inner_join(., tabla_regiones) %>% 
  return(.)}

#hash table: regionalización.=====
tribble(~REGION,        ~ENT_CORTO,           ~CVE_ENT,
        "Centro_norte", "Aguascalientes",     "01",     
        "Centro_norte", "Guanajuato",         "11",    
        "Centro_norte", "Querétaro",          "22",     
        "Centro_norte", "San Luis Potosí",    "24",    
        "Centro_norte", "Zacatecas",          "32",     
        "Centro_sur",   "Ciudad de México",   "09",    
        "Centro_sur",   "México",             "15",     
        "Centro_sur",   "Morelos",            "17",    
        "Este",         "Hidalgo",            "13",     
        "Este",         "Puebla",             "21",    
        "Este",         "Tlaxcala",           "29",     
        "Este",         "Veracruz",           "30",    
        "Noreste",      "Coahuila",           "05",     
        "Noreste",      "Nuevo León",         "19",    
        "Noreste",      "Tamaulipas",         "28",     
        "Noroeste",     "Baja California",    "02",    
        "Noroeste",     "Baja California Sur","03",     
        "Noroeste",     "Chihuahua",          "08",    
        "Noroeste",     "Durango",            "10",     
        "Noroeste",     "Sinaloa",            "25",    
        "Noroeste",     "Sonora",             "26",     
        "Oeste",        "Colima",             "06",    
        "Oeste",        "Jalisco",            "14",     
        "Oeste",        "Michoacán",          "16",    
        "Oeste",        "Nayarit",            "18",     
        "Sur_este",     "Campeche",           "04",    
        "Sur_este",     "Quintana Roo",       "23",     
        "Sur_este",     "Tabasco",            "27",    
        "Sur_este",     "Yucatán",            "31",     
        "Sur_oeste",    "Chiapas",            "07",    
        "Sur_oeste",    "Guerrero",           "12",     
        "Sur_oeste",    "Oaxaca",             "20" 
        ) ->tabla_regiones 

arreglar_y_unir(presidentes_municipales) %>% 
  rename(POmenor5000=`PL<5000`) %>%                                                
  select(sexo, partido_coalicion, POB_TOT, IM, POmenor5000, REGION) %>%                   
  mutate_if(is.character, as.factor) %>%                                           
  mutate(partido_coalicion=fct_lump(partido_coalicion, 6, other_level="Otro")) %>% 
  mutate(partido_coalicion=fct_relevel(partido_coalicion,"PRI")) ->presidentes
```


Las variables que consideraremos son las siguientes: 

Variable  | Descripción
----------|----------------------------------------------
sexo      | Sexo del presidente o presidenta municipal (H o M)^[Retomamos la codificación de la base de datos.]
POmenor5000| % De población que vive en localidades de menos de 5000 habitantes. Proxy de ruralidad. 
partido_coalición | Partido gobernante o cabeza de coalición gobernante.
POB_TOT   | Población total del municipio.
IM        | Índice de Marginación.
REGION    | Región geográfica.

Table: Variables a modelar. 

###Desciptivos de la base de datos. 

```{r, descriptivos, results= 'asis', echo=FALSE}
library(pander)
summary(presidentes) %>% 
  pander(., caption="Sumario de la base de datos", missing="")
```

##Un modelo lineal con `glm()`

###La ordenada al origen de un modelo logit. 

Para introducirnos al ajuste e interpretación de los coeficientes de los modelos logit comenzaremos por el más simple de todos: uno que no tiene variables predictoras. Por el momento no nos preocuparemos por las pruebas de hipótesis y los estadísticos de ajuste, sólo consideraremos los coeficientes. 
La formula en R para este de ordenada al origen modelo es `sexo~1`, es decir, utilizamos solamente el lado izquierdo y del lado derecho ubicamos la constante `1`. El único coeficiente que estimaremos es el de la ordenada al origen: el logaritmo de la razón de probabilidad de $y=1$. Para saber a qué se refiere $y=1$ es necesario conocer cuál es la categoría de referencia de la variable, es decir, `y=0`. 

En R las variables categóricas que utilizamos como dependientes en un modelo logit corresponden al tipo de datos `factor`. Un factor es, técnicamente, una variable numérica compuesta de enteros sucesivos a partir de 1. Cada entero es un nivel o categoría de la variable y está acompañado de una etiqueta que nos facilita recordar a qué categoría corresponde. Los modelos logit binomiales aceptan para las variables dicotómicas codificadas como 0 y 1, lo cuál podría ser problemático si, como numéricos, los factores comienzan con 1. Como la estructura del tipo de datos factor es conocida las funciones que estiman modelos logit convierten internamente a la variable categórica/factor en una variable codificada como 0/1. No es necesario recodificar la variable o convertirla en dummy, esto se procesa de manera transparente para el usuario. Usando la función `levels()` podemos consultar los niveles o categorías de un factor e identificar al nivel 1, que será el nivel de referencia en el modelo, es decir, $y=0$. Para variable dicotómicas el nivel 2 del factor equivale a $y=1$.
Veamos cuales son los valores de  y para la variable sexo del conjunto de datos: 

```{r}
levels(presidentes$sexo)
ref(presidentes)            #ref() es una función personalizada para reportar el nivel 1 de un conjutno de factores
```

y=0 es hombre y y=1 es mujer. Entonces el modelo de la ordenada al origen nos reportará el logaritmo de la razón de probabilidad de que un municipio esté gobernado por una mujer. 

```{r, modelo1}
#Modelo logit sin variables independientes
presidentes %>% 
  glm(sexo~1, family=binomial(), data=.) ->molige1
molige1
```

La constante para la variable dependiente (Intercept) es  -1.735 

*¿Qué significa ese número?* De manera directa que el logaritmo de la razón de probabilidad de $y=1$ es -1.735. Sin embargo interpretar un logaritmo de razón de probabilidad no es lo más intuitivo. Al menos por el signo negativo sabemos que la probabilidad de $y=1$ es menor a la de $y=0$: hay menos mujeres presidentas municipales que hombres. Para hacer más intuitiva la interpretación podemos desandar el camino de la función de enlace de la ecuación (@logit). El primer paso es quitar el logaritmo y convertir al coeficiente en una razón de probabilidad: exponenciar el logaritmo. En R lo hacemos con la función `exp()`, que nos regresa el exponencial de un logaritmo. El exponencial de -1.735 es 0.176, redondeado. Por cada presidente municipal hay 0.176 presidentas o, lo que es lo mismo, hay 5.67 presidentes municipales por cada presidenta.    

*¿De dónde salió?* Sobre 1881 presidentes municipales 282 son mujeres y 1599 hombres. Por lo tanto la probabilidad de presidenta municipal es 282/1881, es decir, 0.1499. Utilizando el lado derecho de la ecuación (@logit) podemos convertir a esta probabilidad en una razón de probabilidad: con $p1=0.1499$, $p1/(1-p1)=0.1499/(1-0.1499)=0.176$: aquí está nuestra razón de probabilidad, cuyo logaritmo es -1.735, el coeficiente que reportó el modelo. 

##Estimación de $\beta_1$

El segundo modelo que ajustaremos incluye una variable independiente, a la que simplificaremos para facilitar la exposición. Esta variable es dicotómica y refiere al partido político: tendrá valor 0 si el partido es el PRI y valor 1 si es otro. 

```{r, modelo2}
presidentes %>% 
  mutate(partido_coalicion=fct_lump(partido_coalicion, 1, other_level="Otro")) %>% 
  glm(sexo~partido_coalicion, family=binomial(), data=.) ->molige2  
molige2
exp(coef(molige2))
``` 

La salida de `glm()` incluye ahora un segundo coeficiente, llamado `partido_coalicionOtro`. Ese coeficiente es el logaritmo de la razón de probabilidad de presidenta municipal cuando el partido gobernante en el municipio *no* es el PRI. La pendiente negativa de $\beta_1$ nos indica que, cuando gobierna otro partido, las probabilidades de presidenta municipal bajan. 

Podríamos obtener este mismo coeficiente a través de una tabla de contingencia y... vamos a hacerlo. 

```{r}
presidentes %>% 
  mutate(partido_coalicion=fct_lump(partido_coalicion, 1, other_level="Otro")) %>% 
  select(sexo, partido_coalicion) %>% 
  table()
```

¿Cuál es la probabilidad de ser presidenta municipal cuando el partido es el PRI? 154/687, es decir, el número de mujeres entre todos los presidentes y presidentas municipales tricolores. Esto equivale a 0.224163. Cuando es otro partido es 0.1405049, 128 presidentas sobre un total 911. Entonces podemos calcular la razón de probabilidad de presidenta para Otro partido vs el PRI: 0.1405049/0.224163, que es igual 0.626798, cuyo logaritmo es -0.4671309, el coeficiente que nos regresó el modelo. 

##Modelo logit con dos variables independientes. 

En el Modelo 2 estimamos el cambio en el logaritmo de la razón de probabilidad de la variable sexo a medida que cambia el partido político y encontramos que las probabilidades de presidenta municipal bajan cuando el partido gobernante no es el PRI. Sin embargo es posible que el PRI no sea la variable explicativa y que tengamos alguna variable confusora que nos está generando problemas. Pensemos en una hipótesis: el PRI gobierna muchos municipios rurales y quizás los municipios rurales sean más propensos a elegir presidentas que presidentes. En este caso la ruralidad sería una variable confusora, nos confunde haciéndonos creer que el PRI es una variable efectiva para explicar la probabilidad presidenta municipal, cuando en realidad es ella --la ruralidad-- la que explica ambas: que el gobierno esté encabezado por una mujer *y* que esté encabezado por el PRI. Los modelos logit nos permiten controlar este tipo de situaciones y estimar los valores de $\beta_1$ descontando el efecto de los demás predictores. Si la hipótesis de la ruralidad como confusora es correcta agregando al modelo una medida de ruralidad, el efecto del PRI sobre la probabilidad de presidenta municipal debería desaparecer. 

Nótese que incluiremos del lado derecho tanto predictores categóricos como continuos. La interpretación de los predictores continuos es similar a la de los categóricos, aunque debemos tener en consideración su escala, ya que no varían entre 0 y 1 sino que adquieren más variados. El coeficiente $\beta$ para una variable continua indica el cambio en el logaritmo de la razón de probabilidad de y por cada incremento de una unidad de la variable continua. Profundizaremos este punto cuando interpretemos el Modelo 3.

La formula que utilizaremos es `sexo~partido_coalicion+POmenor5000`. Expresaremos los coeficientes redondeados, de lo contrario R nos los regresa en notación científica.

```{r, modelo3}
presidentes %>%
  mutate(partido_coalicion=fct_lump(partido_coalicion, 1, other_level="Otro")) %>% 
  glm(sexo~partido_coalicion+POmenor5000, family=binomial(), data=.) -> molige3
round(coef(molige3), 6)
```

El coeficiente correspondiente a POmenor5000 es 0.006491, que interpretamos de la siguiente manera: por cada unidad porcentual de adicional de población viviendo en localidades menores a 5000 habitantes el logaritmo de la razón de probabilidad de presidenta municipal aumenta 0.0006491. Más adelante veremos maneras menos rebuscadas de comunicar estos resultados, por ahora consideremos que nuestra hipótesis de la ruralidad tiene algo de evidencia a favor: la probabilidad de presidenta municipal aumenta con la ruralidad, medida de esta manera un tanto brusca. ¿Es el efecto de la ruralidad suficiente para hacer desaparecer el efecto del PRI vs Otros? No, los demás partidos mantienen una probabilidad de presidenta menor a la del PRI.

##Modelo logit con múltiples variables dependientes. 

Otra hipótesis sustantiva que podemos considerar es que no es la ruralidad, sino el Índice de Marginación la confusora. Iremos más allá y propondremos un modelo más sofisticado que incluye otras variables que controlaremos: población total del municipio, Índice de Marginación y región. Para hacer más granular la hipótesis partidaria incluiremos más partidos, un total de 6: PRI, PAN, PRD, PVEM, PMC, PT y Otros, a los que controlaremos por ruralidad, población total e Índice de marginación. Al cambiar la codificación de la variable partido_coalición el modelo 4 ya no será directamente comparable con los 3 anteriores, es decir, ya no serán modelos anidados. 

```{r, modelo4}
presidentes %>% 
  glm(sexo~partido_coalicion+POmenor5000+POB_TOT+IM, family=binomial(), data=.) -> molige4
round(coef(molige4), 6)
```

El primer dato interesante es que hay un partido con una probabilidad de presidenta todavía más alta que la del PRI: el Verde Ecologista.^[Si pensó que era un partido de izquierda necesita rodearse de más feministas.] Controlando por población, ruralidad e Índice de Marginación PRI y PVEM tienen probabilidades más altas de presidenta. Asimismo encontramos que, por cada punto de incremento de IM $log(p_{presidenta}/(1-p_{presidenta}))$ aumenta 0.032.
Si bien los resultados no son concluyentes y quizás deberíamos incorporar más hipótesis sustantivas orientadas a explicar la prevalencia de presidentas municipales, por no hablar del mecanismo que hace el PRI y PVEM sean buenos predictores de presidentas municipales. De todos modo con  este modelo podríamos concluir que el partido es relevante para explicar si a un municipio lo gobierna un hombre o una mujer. 

##Pruebas de significancia. 

Hasta ahora hemos tratado a los coeficientes como si fueran un parámetro: el verdadero valor de la pendiente, suficientemente informativo por sí mismo. Sin embargo no lo son, se trata estimaciones y, como tales, no son completamente precisas. En sentido estricto son el centro de una distribución de probabilidades de coeficientes, el valor más probable, pero no el único posible. Cuan dispersa es esa distribución nos lo indica el error estándar: cuanto mayor el error más dispersos estarán los coeficientes, cuanto menor, menos dispersos. 


```{r}
data.frame(`sigma0.3media0`=rnorm(100000, 0, 0.3), `sigma0.1media0`=rnorm(100000, 0, 0.1), `sigma0.3media1`=rnorm(100000, 1, 0.3), `sigma01media1`=rnorm(100000, 1, 0.1)) %>% 
  gather() %>% 
  ggplot(aes(x=value, fill=key)) + 
  geom_density(alpha=0.5) + 
  theme_minimal() 
```

Todos los coeficientes estimados del modelo cuatro son numéricamente distintos de 0: aparentemente tienen un efecto  sobre la probabilidad de presidenta. Pero si los consideramos el centro de una distribución de coeficientes deberíamos contemplar la posibilidad --probabilidad-- de que el verdadero coeficiente fuera otro, quizás 0. En concreto, deberíamos realizar una prueba de hipótesis en la que comparamos a los coeficientes obtenidos en el Modelo 4 con unos coeficientes hipotéticos iguales a 0. No es necesario que lo hagamos cada vez, el sumario de los modelos lineales generalizados nos presenta los resultados de esa prueba de hipótesis. El p-value de la prueba de hipótesis nos indica la probabilidad de obtener unos coeficientes como los nuestros dada la hipótesis de nulidad según la cuál los coeficientes verdaderos son 0. Si esa probabilidad es muy baja podemos rechazar la hipótesis de nulidad y considerar que nuestros coeficientes son diferentes de 0. 

Obtenemos el sumario de un modelo con la función genérica `summary()`. Observemos la quinta columna del sumario, que reporta los p-value que especificamos en el párrafo anterior. 

```{r}
summary(molige4)
```

La probabilidad de obtener los coeficientes del Modelo 4 dada la hipótesis de que el verdadero coeficiente es 0 es baja en todos los casos, excepto para el IM. En este caso el p-value es 0.6922, es decir, es muy probable que una distribución al azar de coeficientes con media 0 produzca el coeficiente que estimó el modelo. Concluimos que no es significativamente diferente de 0 y que el IM no tiene un efecto sobre la probabilidad de presidenta. Presidentes y presidentas se distribuyen de manera independiente al Índice de Marginación de un municipio. 

¿Qué hay de los modelos anteriores? Para facilitar la comparación los reportaremos en una tabla formateada, usando la función `htmlreg()` del paquete `texreg()`. Esta función recibe una lista de modelos y nos regresa una tabla formateda con esos modelos. Para salidas en consola utilizamos `screenreg()` y `texreg()` para tablas formateadas en $\LaTeX$. 

```{r, results='asis'}
library(texreg)
htmlreg(list(molige1, molige2, molige3), caption="Comparación de modelos logit")
```

#Presentación de resultados. 

##Intervalos de confianza. 

Otra forma de presentar los coeficientes estimados por el modelo dando cuenta del error de estimación es presentar un intervalo, en lugar de una estimación puntual. Estos intervalos dan cuenta del error haciéndose más extensos a medida que el error es más grande. Se estiman a partir de un nivel de confianza, generalmente 90, 95 o 99%. 
En R los obtenemos con la función `confint()`, que lleva como primer argumento el nombre del modelo de que queremos extrae los intervalos de confianza. Por defecto los calcula con una confianza del 95%, aunque los podemos especificar con el argumento  `level=confianza`, donde confianza es un número mayor que 0 y menor que 1. 

```{r}
confint(molige4)                        #Intervalo de confianza al 95% para el Modelo 4
exp(confint(molige4, level=0.99))    #Intevalo de confianza de las razones de probabilidad al 99% para el Modelo 4
```

##Gráfico de coeficientes. 

A partir de los intervalos de confianza de los coeficientes se puede obtener una salida gráfica de la estimación del modelo, que es especialmente útil para ubicar las pendientes relativas de cada predictor. No es difícil hacer el gráfico nosotros mimos, pero la función `coefplot::coeffplot()` grafica directamente los coeficientes y regresa un objeto de la clase `ggplot2`, por lo que podemos personalizar el estilo visual, sin alterar el contenido. La sintaxis es  `coefplot(modelo)`, donde `modelo` es un objeto de la clase `glm`. 

```{r, fig.cap="Efecto de algunas variables sobre la probabilidad de presidenta municipal"}
library(coefplot)
coefplot(molige4)  + 
  theme_minimal() + 
  labs(title="Estimación de coeficientes con error estandar", 
       x="Estimación", 
       y="Variable", 
       caption="Elaboración propia con datos del SNIM y CONAPO")
```

En el gráfico podemos ver que, dentro del intervalo marcado por el error estandar, IM está sobre la línea que marca el valor 0. POB_TOT y POmenor5000 parecen estar cerca, pero sin tocar la línea. Definitivamente necesitaremos consultar la tabla para tener identificar la significancia de esos coeficientes. La constante u ordenada al origen es puramente teórica: señala el logaritmo de la razón de probabilidad de presidenta en un municipio gobernado por el PRI con 0% de población en localidades de menos de 5000 habitantes, 0 habitantes y 0 Índice de Marginación. No tiene una interpretación sustantiva.  

##Tabla y gráfico de efectos totales promedio. 

La razón de probabilidad o el logaritmo de la razón de probabilidad con el que los modelos logit reportan los coeficientes son matemáticamente correctos, pero sinceramente no son la forma más intuitiva de dar cuenta de la magnitud del cambio de $y$ cuando cambia $x$. Sería mejor poder expresarlo como probabilidades directas o como variación en las probabilidades, más que en las razones de probabilidad. Como esto es R, hay una librería para eso, o mejor dicho 2. Para obtener los efectos promedio totales de unos coeficientes utilizamos la librería `effects::`, cortesía de John Fox^[Además de  `effects` Fox a contribuido a la comunidad de R con las librerías `car::` para diagnostico de regresiones y  `sem::` para ecuaciones estructurales.]. `effects::` incluye salidas en tabla y gráficas de los efectos absolutos de un predictor, incluyendo salidas para los errores. Para obtener los efectos marginales podemos usar `mfx::`.

La función  `effects::allEffects()` produce una tabla con los efectos totales a partir de un modelo lineal. Es posible generar un gráfico de los efectos pasando el objeto resultante a la función plot. En este caso se presenta el efecto total y un intervalo de confianza del 95%. `plot(allEffects))` genera un gráfico para cada predictor y, si es continuo, grafica la pendiente y si es categórico el efectos de cada categoría de la variable. 

```{r}
library(effects)
allEffects(molige4)
plot(allEffects(molige4))
```

##Sumario de efectos marginales. 

La función `logitmfx()` no recibe a un objeto de la clase `glm`, sino que requiere especificar el modelo dentro de la llamada. La sintaxis es similar a la de `glm()`: formula, datos. Es un poco más rudimentaria que `effects()`, pero es mejor que calcular manualmente los efectos marginales. 

```{r}
round(mfx::logitmfx(sexo~partido_coalicion+POmenor5000+POB_TOT+IM, presidentes)$mfxest, 6) 
```
