---
title: "Modelos logit con R"
author: "Martín Paladino"
date: "5 de abril de 2017"
output:
  html_document:
    highlight: textmate
    number_sections: yes
    theme: journal
    toc: yes
---

```{r, include=F}
knitr::opts_chunk$set(echo = TRUE, warning= FALSE, message = FALSE, fig.width = 8, fig.height = 8)
library(tidyverse)
library(magrittr)
library(pander)
library(knitr)
library(forcats)
#Función para imprimir las categorías de referencia: y o x =0. 

ref <- function(.){print(summarise_if(., is.factor, funs(levels(.)[1])))}

```

    
#Introducción.
Los [modelos lineales](martinpaladino.github.io/modelos_lineales_con_R.html) nos permiten predecir el valor de una variable a partir del valor de otra u otras. En su formulación original se desarrollaron para variables dependientes continuas, es decir, para estimar los valores que toma y para cada valor de x a partir de una ordenada al origen y una o más pendientes. Sin embargo puede ser de interés tomar como variables dependiente a una categórica y eso es lo que hacen los modelos logit, también conocidos como regresión logística. Claro que no es muy útil predecir cualquier valor de $y$ dadas $x_1$, $x_2$, $x_n$, dado que $y_{categórica}$ solamente puede adquirir dos valores, 0 y 1. Lo que buscaremos predecir son las probabilidades de 0 o 1. Es decir, dado cierto valor de $x$ ¿cuál es la probabilidad de $y_0$ y de $y_1$? 
Podríamos simplificarnos la tarea y ajustar sin modificaciones un modelo lineal con la forma de la ecuación 1. 

(@lineal_simple) $y=\beta_0+\beta_1x+...\beta_ix$

Le pediríamos al modelo que predijera 0 o 1, al fin y al los podríamos considerar valores numéricos e interpretar adecuadamente. Sin embargo estaríamos violando los supuestos de un modelo lineal: la distribución de probabilidad de y categórica no es normal. Sin embargo no todo está perdido. Si y no se ajusta a una distribución normal se puede ajustar a otras distribuciones y, para y dicotómica, podemos asumir que se ajusta a una distribución binomial. En ese caso podemos usar la ecuación (@logit)

(@logit) $ln(\frac{p_1}{1-p_1})=\beta_0+\beta_1x+...\beta_ix$

El lado derecho es igual de cualquier modelo lineal, pero el lado izquierdo tiene peculiaridades que vale la pena comentar. Como mencionamos, ya no buscamos al valor de $y$ como una combinación lineal de los valores de $x_1...X_i$. Lo que buscamos es el *logaritmo de las razones de probabilidad de $y=1$*, que obtenemos dividiendo las probabilidades 1 por la probabilidad de 0.^[Como sabemos que la probabilidad de varía entre 0 y 1 entonces 1 menos la probabilidad de de 1 es igual a la probabilidad de 0.] El [Anexo I. Probabilidades y razones de probabilidad.] desarrolla algunas propiedades de las razones de probabilidad. 

#Ajuste  de modelos logit con `glm()`

Los modelos logit forman parte de lo que conocemos como Modelos Lineales Generalizados. Utilizamos la expresión generalizados porque son un marco general dentro del que caben casos particulares. Los modelos lineales con y continua son un caso particular de los generalizados: aquellos con una distribución normal y una función de enlace directa^[Estimamos directamente el valor y.]. Los modelos logit son un caso particular de los modelos lineales generalizados en los que la distribución es binomial y la función de enlace el logaritmo de las razones de probabilidad, es decir, la función logit que les da nombre. 

La función `glm()` de R nos permite ajustar modelos lineales de muchos tipos, incluyendo los que ajustamos con `lm()`, modelos de Poisson y los logit en los que nos enfocaremos. 
La sintaxis básica para obtener un modelo lineal es `glm(dependiente~independiente1+independiente2, family=binomial(), data=datos")`.

El primer argumento es un objeto de la clase fórmula. A la izquierda del signo  `~` ubicamos a la variable dependiente y a la derecha, unidos por el signo `+` las independientes, si no estamos especificando una interacción entre variables. 

El segundo, `family=binomial()`, especifica la función de probabilidad que utilizaremos. Para modelos logit es una función binomial. Dentro de los paréntesis se puede especificar la función de enlace. Para la familia de distribuciones binomial `glm()` por defecto usa una función logit. Si nos interesa una función probit deberíamos especificar `link=probit`. 

El tercero apunta a un data.frame en el que están los datos. Los nombres de columna del data.frame deben coincidir con las variables especificadas en la fórmula, aunque podría contener más variables que serán descartadas. En el caso de hacer previamente una manipulación de datos encadenada con el operador ` %>%` usamos `.` como sustituto anónimo de los datos. 

##Presentación de los datos.

Introduciremos una nueva base de datos y una hipótesis sustantiva para que nos sirva de guía. La base elaborada por el Sistema de Información Municipal del Instituto Nacional para el Federalismo y el Desarrollo Municipal tiene información sobre los presidentes municipales de México, incluyendo el sexo, partido y título. Como incluye  el número de municipio y entidad federativa podemos combinar esta base de datos con la de CONAPO para agregar más variables. La base de datos tienen algunos problemas que requieren manipulación y que hemos atendido en otra parte(AGREGAR EL ENLACE). Trabajaremos con la base ya limpia, con una N=1881. 
Queremos explorar qué variables explican que un municipio tenga presidente o presidenta municipal. Nuestra primer hipótesis es que el partido político es una buena variable explicativa, considerando que los partidos progresistas son más propensos a apoyar candidaturas femeninas. Sin embargo otras variables podrían intervenir: la ruralidad/urbanidad del municipio, el Grado de Marginación, la región, etc. 


```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(stringr)
#Carga base presidentes municipales ====
presidentes_municipales <- 
  read_csv("./datos/presidentes_municipales.csv", col_types = cols(ap_materno = col_character(), fecha_actualizacion = col_character(), pdo_gob_ini = col_character()))
names(presidentes_municipales)[1] <- "estado"
#Carga base marginación. ====
marginacion <- 
  read_csv("./datos/Base_Indice_de_marginacion_municipal_90-15.csv", col_types = cols(`AÑO` = col_character()), 
    locale = locale(encoding = "UTF-8")) %>%  
      mutate (POB_TOT=gsub(" ","", POB_TOT)) %>%
      mutate(POB_TOT=as.integer(POB_TOT)) %>%
      filter(ENT!="Nacional" & AÑO=="2015")
names(marginacion)[1] <- "CVEMUN" 

#Función para arreglar la base presidentes y unirla con marginación. 
arreglar_y_unir <- function(.) {
  separate(.,integrantes, into=("cabeza_coalicion")) %>%                  
  dplyr::mutate(partido_coalicion=ifelse(is.na(cabeza_coalicion), partido, cabeza_coalicion)) %>%  
    mutate(partido_coalicion=ifelse(partido_coalicion=="CPU", "PAN", partido_coalicion)) %>% 
    mutate (id_estado= ifelse(str_length(id_estado)==1, 
                            paste0("0", id_estado), 
                            id_estado)) %>% 
    mutate(id_municipio= ifelse(str_length(id_municipio)==1, 
                              paste0("00", id_municipio),
                              ifelse(str_length(id_municipio)==2, 
                                     paste0("0", id_municipio), 
                                     id_municipio))) %>% 
    mutate(prof=ifelse(titulo=="C.", "C", "P")) %>% 
  mutate(CVEMUN=paste0(id_estado, id_municipio)) %>% 
  inner_join(., marginacion) %>% 
  inner_join(., tabla_regiones) %>% 
  return(.)}

#hash table: regionalización.=====
tribble(~REGION,        ~ENT_CORTO,           ~CVE_ENT,
        "Centro_norte", "Aguascalientes",     "01",     
        "Centro_norte", "Guanajuato",         "11",    
        "Centro_norte", "Querétaro",          "22",     
        "Centro_norte", "San Luis Potosí",    "24",    
        "Centro_norte", "Zacatecas",          "32",     
        "Centro_sur",   "Ciudad de México",   "09",    
        "Centro_sur",   "México",             "15",     
        "Centro_sur",   "Morelos",            "17",    
        "Este",         "Hidalgo",            "13",     
        "Este",         "Puebla",             "21",    
        "Este",         "Tlaxcala",           "29",     
        "Este",         "Veracruz",           "30",    
        "Noreste",      "Coahuila",           "05",     
        "Noreste",      "Nuevo León",         "19",    
        "Noreste",      "Tamaulipas",         "28",     
        "Noroeste",     "Baja California",    "02",    
        "Noroeste",     "Baja California Sur","03",     
        "Noroeste",     "Chihuahua",          "08",    
        "Noroeste",     "Durango",            "10",     
        "Noroeste",     "Sinaloa",            "25",    
        "Noroeste",     "Sonora",             "26",     
        "Oeste",        "Colima",             "06",    
        "Oeste",        "Jalisco",            "14",     
        "Oeste",        "Michoacán",          "16",    
        "Oeste",        "Nayarit",            "18",     
        "Sur_este",     "Campeche",           "04",    
        "Sur_este",     "Quintana Roo",       "23",     
        "Sur_este",     "Tabasco",            "27",    
        "Sur_este",     "Yucatán",            "31",     
        "Sur_oeste",    "Chiapas",            "07",    
        "Sur_oeste",    "Guerrero",           "12",     
        "Sur_oeste",    "Oaxaca",             "20" 
        ) ->tabla_regiones 

arreglar_y_unir(presidentes_municipales) %>% 
  rename(POmenor5000=`PL<5000`) %>%                                                
  select(sexo, partido_coalicion, POB_TOT, IM, POmenor5000) %>%                   
  mutate_if(is.character, as.factor) %>%                                           
  mutate(partido_coalicion=fct_lump(partido_coalicion, 6, other_level="Otro")) %>% 
  mutate(partido_coalicion=fct_relevel(partido_coalicion,"PRI")) ->presidentes
```


Las variables que consideraremos son las siguientes: 

Variable  | Descripción
----------|----------------------------------------------
sexo      | Sexo del presidente o presidenta municipal (H o M)^[Retomamos la codificación de la base de datos.]
POmenor5000| % De población que vive en localidades de menos de 5000 habitantes. Proxy de ruralidad. 
partido_coalición | Partido gobernante o cabeza de coalición gobernante.
POB_TOT   | Población total del municipio.
IM        | Índice de Marginación.

Table: Variables a modelar. 

###Desciptivos de la base de datos. 

```{r, descriptivos, results= 'asis', echo=FALSE}
library(pander)
summary(presidentes) %>% 
  pander(., caption="Sumario de la base de datos", missing="")
```

##Un modelo lineal con `glm()`

###La ordenada al origen de un modelo logit. 

Para introducirnos al ajuste e interpretación de los coeficientes de los modelos logit comenzaremos por el más simple de todos: uno que no tiene variables predictoras. Por el momento no nos preocuparemos por las pruebas de hipótesis y los estadísticos de ajuste, sólo consideraremos los coeficientes. 
La formula en R para este de ordenada al origen modelo es `sexo~1`, es decir, utilizamos solamente el lado izquierdo y del lado derecho ubicamos la constante `1`. El único coeficiente que estimaremos es el de la ordenada al origen: el logaritmo de la razón de probabilidad de $y=1$. Para saber a qué se refiere $y=1$ es necesario conocer cuál es la categoría de referencia de la variable, es decir, `y=0`. 

En R las variables categóricas que utilizamos como dependientes en un modelo logit corresponden al tipo de datos `factor`. Un factor es, técnicamente, una variable numérica compuesta de enteros sucesivos a partir de 1. Cada entero es un nivel o categoría de la variable y está acompañado de una etiqueta que nos facilita recordar a qué categoría corresponde. Los modelos logit binomiales aceptan para las variables dicotómicas codificadas como 0 y 1, lo cuál podría ser problemático si, como numéricos, los factores comienzan con 1. Como la estructura del tipo de datos factor es conocida las funciones que estiman modelos logit convierten internamente a la variable categórica/factor en una variable codificada como 0/1. No es necesario recodificar la variable o convertirla en dummy, esto se procesa de manera transparente para el usuario. Usando la función `levels()` podemos consultar los niveles o categorías de un factor e identificar al nivel 1, que será el nivel de referencia en el modelo, es decir, $y=0$. Para variable dicotómicas el nivel 2 del factor equivale a $y=1$.
Veamos cuales son los valores de  y para la variable sexo del conjunto de datos: 

```{r}
levels(presidentes$sexo)
ref(presidentes)            #ref() es una función personalizada para reportar el nivel 1 de un conjutno de factores
```

y=0 es hombre y y=1 es mujer. Entonces el modelo de la ordenada al origen nos reportará el logaritmo de la razón de probabilidad de que un municipio esté gobernado por una mujer. 

```{r, modelo1}
#Modelo logit sin variables independientes
presidentes %>% 
  glm(sexo~1, family=binomial(), data=.) ->molige1
molige1
```

La constante para la variable dependiente (Intercept) es  -1.735 

*¿Qué significa ese número?* De manera directa que el logaritmo de la razón de probabilidad de $y=1$ es -1.735. Sin embargo interpretar un logaritmo de razón de probabilidad no es lo más intuitivo. Al menos por el signo negativo sabemos que la probabilidad de $y=1$ es menor a la de $y=0$: hay menos mujeres presidentas municipales que hombres. Para hacer más intuitiva la interpretación podemos desandar el camino de la función de enlace de la ecuación (@logit). El primer paso es quitar el logaritmo y convertir al coeficiente en una razón de probabilidad: exponenciar el logaritmo. En R lo hacemos con la función `exp()`, que nos regresa el exponencial de un logaritmo. El exponencial de -1.735 es 0.176, redondeado. Por cada presidente municipal hay 0.176 presidentas o, lo que es lo mismo, hay 5.67 presidentes municipales por cada presidenta.    



*¿De dónde salió?* Sobre 1881 presidentes municipales 282 son mujeres y 1599 hombres. Por lo tanto la probabilidad de presidenta municipal es 282/1881, es decir, 0.1499. Utilizando el lado derecho de la ecuación (@logit) podemos convertir a esta probabilidad en una razón de probabilidad: con $p1=0.1499$, $p1/(1-p1)=0.1499/(1-0.1499)=0.176$: aquí está nuestra razón de probabilidad, cuyo logaritmo es -1.735, el coeficiente que reportó el modelo. 

```{r, tabla_sexo, echo=FALSE, results='asis'}
`y=` <- c(0,1)
Conteos <- table(presidentes$sexo)
Probabilidades <- c(Conteos[1]/sum(Conteos), Conteos[2]/sum(Conteos))
`Razón de probabilidad` <- c(1, Probabilidades[2]/(1-Probabilidades[2]))
`Logaritmo RP` <- log(`Razón de probabilidad`)
pander(rbind(`y=`,Conteos, Probabilidades, `Razón de probabilidad`, `Logaritmo RP`), caption="Presidentes y presidentas municipales")
```

##Estimación de $\beta_1$

El segundo modelo que ajustaremos incluye una variable independiente, a la que simplificaremos para facilitar la exposición. Esta variable es dicotómica y refiere al partido político: tendrá valor 0 si el partido es el PRI y valor 1 si es otro. 

```{r, modelo2}
presidentes %>% 
  mutate(partido_coalicion=fct_lump(partido_coalicion, 1, other_level="Otro")) %>% 
  glm(sexo~partido_coalicion, family=binomial(), data=.) ->molige2  
molige2
exp(coef(molige2))
``` 

La salida de `glm()` incluye ahora un segundo coeficiente, llamado `partido_coalicionOtro`. Ese coeficiente es el logaritmo de la razón de probabilidad de presidenta municipal cuando el partido gobernante en el municipio *no* es el PRI. La pendiente negativa de $\beta_1$ nos indica que, cuando gobierna otro partido, las probabilidades de presidenta municipal bajan. 

Podríamos obtener este mismo coeficiente a través de una tabla de contingencia y... vamos a hacerlo. 

```{r, echo=FALSE, results='asis'}
presidentes %>% 
  mutate(partido_coalicion=fct_lump(partido_coalicion, 1, other_level="Otro")) %>% 
  select(sexo, partido_coalicion) %>% 
  table() ->Conteos
Probabilidades <- prop.table(Conteos, 2)
rownames(Probabilidades) <- c("pH", "pM")
`Razón de probalidad presidenta` <- Probabilidades[2,]/Probabilidades[1,]
`RP presidenta Otro` <- c(1, `Razón de probalidad presidenta`[2]/`Razón de probalidad presidenta`[1])
`y=` <- c(0,1)
`log(RP presidenta Otro)` <- log(`RP presidenta Otro`)
pander(rbind(`y=`, Conteos, Probabilidades, `Razón de probalidad presidenta`, `RP presidenta Otro`, `log(RP presidenta Otro)`))
```

¿Cuál es la probabilidad de ser presidenta municipal cuando el partido es el PRI? 154/687, es decir, el número de mujeres entre todos los presidentes y presidentas municipales tricolores. Esto equivale a 0.224163. Cuando es otro partido es 0.1405049, 128 presidentas sobre un total 911. Entonces podemos calcular la razón de probabilidad de presidenta para Otro partido vs el PRI: 0.1405049/0.224163, que es igual 0.626798, cuyo logaritmo es -0.4671309, el coeficiente que nos regresó el modelo. 

##Modelo logit con dos variables independientes. 

En el Modelo 2 estimamos el cambio en el logaritmo de la razón de probabilidad de la variable sexo a medida que cambia el partido político y encontramos que las probabilidades de presidenta municipal bajan cuando el partido gobernante no es el PRI. Sin embargo es posible que el PRI no sea la variable explicativa y que tengamos alguna variable confusora que nos está generando problemas. Pensemos en una hipótesis: el PRI gobierna muchos municipios rurales y quizás los municipios rurales sean más propensos a elegir presidentas que presidentes. En este caso la ruralidad sería una variable confusora, nos confunde haciéndonos creer que el PRI es una variable efectiva para explicar la probabilidad presidenta municipal, cuando en realidad es ella --la ruralidad-- la que explica ambas: que el gobierno esté encabezado por una mujer *y* que esté encabezado por el PRI. Los modelos logit nos permiten controlar este tipo de situaciones y estimar los valores de $\beta_1$ descontando el efecto de los demás predictores. Si la hipótesis de la ruralidad como confusora es correcta agregando al modelo una medida de ruralidad, el efecto del PRI sobre la probabilidad de presidenta municipal debería desaparecer. 

Nótese que incluiremos del lado derecho tanto predictores categóricos como continuos. La interpretación de los predictores continuos es similar a la de los categóricos, aunque debemos tener en consideración su escala, ya que no varían entre 0 y 1 sino que adquieren más variados. El coeficiente $\beta$ para una variable continua indica el cambio en el logaritmo de la razón de probabilidad de y por cada incremento de una unidad de la variable continua. Profundizaremos este punto cuando interpretemos el Modelo 3.

La formula que utilizaremos es `sexo~partido_coalicion+POmenor5000`. Expresaremos los coeficientes redondeados, de lo contrario R nos los regresa en notación científica.

```{r, modelo3}
presidentes %>%
  mutate(partido_coalicion=fct_lump(partido_coalicion, 1, other_level="Otro")) %>% 
  glm(sexo~partido_coalicion+POmenor5000, family=binomial(), data=.) -> molige3
round(coef(molige3), 6)
```

El coeficiente correspondiente a POmenor5000 es 0.006491, que interpretamos de la siguiente manera: *por cada unidad porcentual de adicional de población viviendo en localidades menores a 5000 habitantes el logaritmo de la razón de probabilidad de presidenta municipal aumenta 0.0006491.* Más adelante veremos maneras menos rebuscadas de comunicar estos resultados, por ahora consideremos que nuestra hipótesis de la ruralidad tiene algo de evidencia a favor: la probabilidad de presidenta municipal aumenta con la ruralidad, medida de esta manera un tanto brusca. ¿Es el efecto de la ruralidad suficiente para hacer desaparecer el efecto del PRI vs Otros? No, los demás partidos mantienen una probabilidad de presidenta menor a la del PRI.

##Modelo logit con múltiples variables dependientes. 

Otra hipótesis sustantiva que podemos considerar es que no es la ruralidad, sino el Índice de Marginación la confusora. Iremos más allá y propondremos un modelo más sofisticado que incluye otras variables que controlaremos: población total del municipio, Índice de Marginación y región. Para hacer más granular la hipótesis partidaria incluiremos más partidos, un total de 6: PRI, PAN, PRD, PVEM, PMC, PT y Otros, a los que controlaremos por ruralidad, población total e Índice de marginación. Al cambiar la codificación de la variable partido_coalición el modelo 4 ya no será directamente comparable con los 3 anteriores, es decir, ya no serán modelos anidados. 

```{r, modelo4}
presidentes %>% 
  glm(sexo~partido_coalicion+POmenor5000+POB_TOT+IM, family=binomial(), data=.) -> molige4
round(coef(molige4), 6)
```

El primer dato interesante es que hay un partido con una probabilidad de presidenta todavía más alta que la del PRI: el Verde Ecologista.^[Si pensó que era un partido de izquierda necesita rodearse de más feministas.] Controlando por población, ruralidad e Índice de Marginación PRI y PVEM tienen probabilidades más altas de presidenta. Asimismo encontramos que, por cada punto de incremento de IM $log(\frac{p_{presidenta}}{(1-p_{presidenta})}$ aumenta 0.032.
Si bien los resultados no son concluyentes. Deberíamos incorporar algunas hipótesis sustantivas orientadas a explicar la prevalencia de presidentas municipales, por no hablar del mecanismo que hace el PRI y PVEM sean buenos predictores de presidentas municipales. Los coeficientes sin un marco de hipótesis sustantivas no tienen mucha capacidad explicativa, en este caso nuestro análisis se limita a la descripción orientada por algunas hipótesis generales. 
De todos modo con  este modelo podríamos concluir que el partido es relevante para explicar si a un municipio lo gobierna un hombre o una mujer, una correlación interesante que valdría la pena seguir investigando. 

##Pruebas de significancia. 

Hasta ahora hemos tratado a los coeficientes como si fueran un parámetro: el verdadero valor de la pendiente, suficientemente informativo por sí mismo. Sin embargo no son parámetros, son *estimaciones* y, como tales, no son completamente precisas. En sentido estricto son el centro de una distribución de probabilidades de coeficientes, el valor más probable, pero no el único posible. Cuan dispersa es esa distribución nos lo indica el error estándar: cuanto mayor el error más dispersos estarán los coeficientes, cuanto menor, menos dispersos. 
Todos los coeficientes estimados del modelo cuatro son numéricamente distintos de 0: aparentemente tienen un efecto  sobre la probabilidad de presidenta. Pero si los consideramos el centro de una distribución de coeficientes deberíamos contemplar la posibilidad --probabilidad-- de que el verdadero coeficiente fuera otro, quizás 0. Para minimizar la posibilidad de tratar como un valor distinto de cero a un coeficiente que lo es deberíamos realizar una prueba de hipótesis. En ella que comparamos a los coeficientes obtenidos en el Modelo 4 con unos coeficientes hipotéticos iguales a 0. 

###Estimación manual de la Prueba de Wald. (wonkish)

En modelos logit la prueba de hipótesis que se lleva a cabo para contrastar la hipótesis de que los coeficientes son diferentes de 0 es la prueba de Wald, que estima un estadístico $\theta$ o z de cada coeficiente, a diferencia del estadístico t que ocupamos en los modelos lineales con distribución gaussiana y enlace directo. El estadístico z se obtiene dividiendo al estimado entre el error estándar. Este valor z nos indica el valor del coeficiente normalizado, es decir, denrto una distribución de probabilidad normal con media 0 y desviación estándar 1.^[Una discusión tan profunda como informal sobre este tópico está disponible en [http://stats.stackexchange.com/questions/60074/wald-test-for-logistic-regression]] Cuanto más cercano a 0 el valor z, menos probable que sea diferente de 0. Para saber cuál es esa probabilidad calculamos la función de densidad para ese valor en una distribución normal: ese es nuestro p-value. Cuanto más bajo el p-value menor es la probabilidad de obtener  nuestro coeficiente dada la hipótesis de nulidad. 

```{r, waldtest}
#Estimación de la prueba de Wald en tres pasos. 

#Paso 1. Extraer los coeficientes y los errores estandar del Modelo 4.  

summary(molige4)$coefficients[,1]   #Subconjunto de la lista coeficientes, columna 1: estimados
summary(molige4)$coefficients[,2]   #Subconjunto de la lista coeficientes, columna 2: errores estandar

#Estimar el valor z

z <- summary(molige4)$coefficients[,1]/summary(molige4)$coefficients[,2]
z

#Estimar la probilidad de z en una distribución normal con media 0 y sigma 1. 

p <- (1 - pnorm(abs(z), 0, 1)) * 2  #Usamos pnorm() para estimar la probabilidad, dado que es una función de prob acumulada usamos 1-pnorm()  
p
```

###Demostración gráfica de la prueba de Wald para `partido_PVEM`

```{r, grafico_wald, , fig.cap="Prueba de Wald para dos coeficientes", fig.height=6, echo=FALSE}
#Prueba gráfica para partido_coalicionPVEM z=2.423264 vs. partido_coalicionPVEM=0

normales <- data.frame(H1=seq(-2, 6, length=100), H0=seq(-4, 4, length=100)) 
altura_est <- dnorm(normales$H1, 2.43264, 1)
altura_cero <- dnorm(normales$H0)
normales <- cbind(gather(normales), c(altura_est, altura_cero))
colnames(normales)[3] <- "altura"
ggplot(normales, aes(x=value, y=altura, fill=key)) + 
  geom_area(alpha=0.5) + 
  geom_vline(xintercept=2.43264) + 
  geom_vline(xintercept=0) +
  annotate("label", x=0, y=0.3, label="media=0") +
  annotate("label", x=2.432, y=0.3, label="media=2.432") + 
  geom_point(x=2.43264, y=0.01938) + 
  annotate("label", x=2.4, y=0.01938, label="p-value", hjust=-0.2) +
  labs(x="Coeficiente", 
         y="Probabilidad", 
         fill="Hipótesis") + 
  theme_minimal()

```

No es necesario que hagamos esta prueba cada vez y por separado, el sumario de los modelos lineales generalizados nos presenta los resultados de esa prueba de hipótesis. El p-value de la prueba de Wald nos indica la probabilidad de obtener unos coeficientes como los nuestros dada la hipótesis de nulidad H0 según la cuál los coeficientes verdaderos son 0. Si esa probabilidad es muy baja podemos rechazar la hipótesis de nulidad y considerar que nuestros coeficientes son diferentes de 0. 
Por supuesto, podríamos hacer una prueba de hipótesis con una H0 diferente, por ejemplo, contra la hipótesis de que el verdadero es 2. 

Obtenemos el sumario de un modelo con la función genérica `summary()`. Observemos la quinta columna del sumario, que reporta los p-value que especificamos en el párrafo anterior. 

```{r}
summary(molige4)
```

La probabilidad de obtener los coeficientes del Modelo 4 dada la hipótesis de que el verdadero coeficiente es 0 es baja en todos los casos, excepto para el IM. En este caso el p-value es 0.6922, es decir, es muy probable que una distribución al azar de coeficientes con media 0 produzca el coeficiente que estimó el modelo. Concluimos que no es significativamente diferente de 0 y que el IM no tiene un efecto sobre la probabilidad de presidenta. Presidentes y presidentas se distribuyen de manera independiente al Índice de Marginación de un municipio. Para una discusión sobre las pruebas de hipótesis vea el [Anexo II. Asterisco sobre los asteriscos.]

¿Qué hay de los modelos anteriores? Para facilitar la comparación los reportaremos en una tabla formateada, usando la función `htmlreg()` del paquete `texreg()`. Esta función recibe una lista de modelos y nos regresa una tabla formateda con esos modelos. Para salidas en consola utilizamos `screenreg()` y `texreg()` para tablas formateadas en $\LaTeX$. 

```{r, results='asis'}
library(texreg)
htmlreg(list(molige1, molige2, molige3), caption="Comparación de modelos logit")
```

#Presentación de resultados. 

##Intervalos de confianza. 

Otra forma de presentar los coeficientes estimados por el modelo dando cuenta del error de estimación es presentar un intervalo, en lugar de una estimación puntual. Estos intervalos dan cuenta del error haciéndose más extensos a medida que el error es más grande. Se estiman a partir de un nivel de confianza, generalmente 90, 95 o 99%. 
En R los obtenemos con la función `confint()`, que lleva como primer argumento el nombre del modelo de que queremos extrae los intervalos de confianza. Por defecto los calcula con una confianza del 95%, aunque los podemos especificar con el argumento  `level=confianza`, donde confianza es un número mayor que 0 y menor que 1. 

```{r}
confint(molige4)                        #Intervalo de confianza al 95% para el Modelo 4
exp(confint(molige4, level=0.99))    #Intevalo de confianza de las razones de probabilidad al 99% para el Modelo 4
```

##Gráfico de coeficientes. 

A partir de los intervalos de confianza de los coeficientes se puede obtener una salida gráfica de la estimación del modelo, que es especialmente útil para ubicar las pendientes relativas de cada predictor. No es difícil hacer el gráfico nosotros mimos, pero la función `coefplot::coeffplot()` grafica directamente los coeficientes y regresa un objeto de la clase `ggplot2`, por lo que podemos personalizar el estilo visual, sin alterar el contenido. La sintaxis es  `coefplot(modelo)`, donde `modelo` es un objeto de la clase `glm`. 

```{r, fig.cap="Efecto de algunas variables sobre la probabilidad de presidenta municipal"}
library(coefplot)
coefplot(molige4)  + 
  theme_minimal() + 
  labs(title="Estimación de coeficientes con error estandar", 
       x="Estimación", 
       y="Variable", 
       caption="Elaboración propia con datos del SNIM y CONAPO")
```

En el gráfico podemos ver que, dentro del intervalo marcado por el error estandar, IM está sobre la línea que marca el valor 0. POB_TOT y POmenor5000 parecen estar cerca, pero sin tocar la línea. Definitivamente necesitaremos consultar la tabla para tener identificar la significancia de esos coeficientes. La constante u ordenada al origen es puramente teórica: señala el logaritmo de la razón de probabilidad de presidenta en un municipio gobernado por el PRI con 0% de población en localidades de menos de 5000 habitantes, 0 habitantes y 0 Índice de Marginación. No tiene una interpretación sustantiva.  

##Tabla y gráfico de efectos totales promedio. 

La razón de probabilidad o el logaritmo de la razón de probabilidad con el que los modelos logit reportan los coeficientes son matemáticamente correctos, pero sinceramente no son la forma más intuitiva de dar cuenta de la magnitud del cambio de $y$ cuando cambia $x$. Sería mejor poder expresarlo como probabilidades directas o como variación en las probabilidades, más que en las razones de probabilidad. Como esto es R, hay una librería para eso, o mejor dicho 2. Para obtener los efectos promedio totales de unos coeficientes utilizamos la librería `effects::`, cortesía de John Fox^[Además de  `effects` Fox a contribuido a la comunidad de R con las librerías `car::` para diagnostico de regresiones y  `sem::` para ecuaciones estructurales.]. `effects::` incluye salidas en tabla y gráficas de los efectos absolutos de un predictor, incluyendo salidas para los errores. Para obtener los efectos marginales podemos usar `mfx::`.

La función  `effects::allEffects()` produce una tabla con los efectos totales a partir de un modelo lineal. Es posible generar un gráfico de los efectos pasando el objeto resultante a la función plot. En este caso se presenta el efecto total y un intervalo de confianza del 95%. `plot(allEffects))` genera un gráfico para cada predictor y, si es continuo, grafica la pendiente y si es categórico el efectos de cada categoría de la variable. 

```{r}
library(effects)
allEffects(molige4)
plot(allEffects(molige4))
```

##Sumario de efectos marginales. 

La función `logitmfx()` no recibe a un objeto de la clase `glm`, sino que requiere especificar el modelo dentro de la llamada. La sintaxis es similar a la de `glm()`: formula, datos. Es un poco más rudimentaria que `effects()`, pero es mejor que calcular manualmente los efectos marginales. 

```{r}
round(mfx::logitmfx(sexo~partido_coalicion+POmenor5000+POB_TOT+IM, presidentes)$mfxest, 6) 
```


#Modelos ligit multinomiales. 

Otro caso de los modelos lineales generalizados son los modelos logit multinomiales. Los logit binomiales nos sirven para modelar una variable dependiente categórica dicotómica, pero podría interesarnos modelar una salida politómica, es decir, una categórica con más de dos niveles. 
La función `glm()` no tiene directamente la capacidad de ajustar este tipo de modelos, aunque es posible hacerlo como un tipo especial de regresión de Poisson. Sin embargo, esto requiere mucho  trabajo previo de adecuación de los datos. La función `nnet:multinom()` facilita las cosas, pues conserva una sintaxis similar a la de `glm()` y ajusta rápidamente modelos logit multinomiales.^[Nótese que es necesario instalar el paquete y tenerlo cargado. `nnet::` está disponible en CRAN.]
La salida de un modelo logit multinomial es similar a la de uno binomial, pero como podemos esperar hay más información, que no estamos modelando solamente el evento $y=1$, también $y=2, y=3, ..., y=k$. Los coeficientes se dividen en más tablas. 

##Ajuste de modelos logit multinomiales com `multinom()`

La sintaxis básica es `multinom(formula, data=datos)`. El primer término de la formula puede ser un factor con dos o más niveles y del lado derecho podemos incluir tanto factores como predictores continuos.
Para este ejemplo tomaremos como variable dependiente `partido_coalicion`, una categórica politómica con 6 niveles. La modelaremos como un combinación lineal de la población en localidades de menos de 5000 habitantes, el Índice de Marginación y el sexo del presidente/presidenta municipal. Las dos primeras son contínuas y la útlima categórica: no hay problema, estarán del lado derecho de la fórmula donde se acepta cualquier tipo de variable.  


```{r}
library(nnet)
multinom(partido_coalicion~IM+sexo, data=presidentes) -> molige5
summary(molige5)
```

El sumario nos presenta por separado a los coeficientes y errores estándar. Los coeficientes se interpretan de igual modo que en un logit binomial: son el logaritmo de la razón de probabilidad de $y=k$ cuando cambia $x$. Para cada nivel de la variable dependiente, excepto el de referencia, se presenta una fila en la tabla. Las columnas ordenan a las variables idenpendientes y a la ordenada al orígen. 

En tabla aparte se reportan los errores estándar de cada coeficiente. `multinom()` no calcula los estadísticos z y los p-value de la prueba de Wald, aunque podemos calcularlos facilmente usando el procedimiento del apartado 2.6.1.

```{r}
pruebaz.multinom <- function(modelo) {}
```



#Anexo I. Probabilidades y razones de probabilidad. 

>El momio tiene razones, que la razón desconoce. 

Las razones de probabilidad, también llamadas razones de momio o odds ratio, se obtienen dividiendo la probabilidad de éxito por la de fracaso. En el contexto de los modelos logit binomiales entendemos como éxito a $y=1$ y a $y=0$ como probabilidad de fracaso. Como $y$ tiene sólo dos categorías podemos obtenerlos usando $RP_{y=1}=\frac{p_{y=1}}{1-p_{y=1}}$. Son una transformación de la probabilidad usuales, que varían entre 0 y 1, pero en lugar de eso varían entre 0 y una repetición infinita  de números 9. Si bien la razón de probabilidad se expresa con un solo número tiene una referencia implícita que es el 1. Una razón de probabilidad 1 significa que ambos eventos tienen la misma probabilidad: la obtuvimos dividiendo 0.5 entre 0.5 Una razón de probabilidad mayor que 1 significa que el evento éxito es más probable que el evento fracaso y menor que 1 lo inverso.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
tribble(~fila,~p0, ~p1,
            1,0.1, 0.9,
            2,0.2, 0.8,
            3,0.3, 0.7, 
            4,0.4, 0.6, 
            5,0.5, 0.5, 
            6,0.6, 0.4, 
            7,0.3, 0.7, 
            8,0.2, 0.8, 
            9,0.1, 0.9) %>% 
  mutate(`RP 1`=p1/p0) %>% 
  kable(., caption="Razones de probabilidad de algunos pares de probabilidades")
```

La razón de probabilidad nos da una magnitud de cuanto más probable es un evento que otro. En la cuarta fila de la Tabla 1 encontramos que el evento 1 tiene una razón de probabilidad de 1.5. Esto significa que es un 50% más probable obtener 1 que obtener 0. En la sexta fila la razón de probabilidad de 1 es 0.666: obtener 1 es un 66% menos probable que obtener 0.
Los coeficientes de los modelos logit no se reportan como razones de probabilidad, sino como logaritmos de las razones de probabilidad. Aunque son más difíciles de interpretar que las razones de probabilidad tienen una ventaja: probabilidades iguales se expresan con el 0, una probabilidad superior del evento éxito con un número positivo y una menor con un número negativo. Es decir, permiten una interpretación rápida y simple de las pendients. 
Para pasar del logaritmo de la razón a probabilidad a la razón de probabilidad exponenciamos los coeficientes y$. En R utilizamos la función `exp()`, que nos regresa el exponencial de los datos numéricos que le pasemos. 

#Anexo II. Asterisco sobre los asteriscos. 

En el contextos de los modelos logit --y en todos los demás-- debemos tener muy claro qué hacemos cuando hacemos una prueba de hipótesis y qué interpretación podemos realizar del mismo. En este caso se estima la probabilidad de obtener unos coeficientes como el que obtuvimos en una hipotética distribución de coeficientes que tiene como centro al 0 y una desviación similar a la de nuestros coeficientes. Si esa probabilidad es muy baja podemos rechazar $H_0$, la hipótesis de nulidad que sostiene que el verdadero es 0. Hay un criterio establecido para interpretar que significa *muy baja*. Cuando el p-value es menor a 0.01 se considera que hay mucha evidencia en contra de la hipótesis de nulidad: hay una probabilidad de del 1% de que el verdadero valor sea 0. Esto suele expresarse con tres asteriscos (\*\*\*) al lado del p-value. 
Cuando es menor a 0.05 (\*\*) también podemos rechazar la hipótesis de nulidad, pero aceptando un poco más de incertidumbre: hay una probabilidad del 5% de que una distribución de coeficientes centrada en el 0 contenga nuestros coeficientes y así con p-values todavía más altos. Las pruebas de hipótesis no eliminan la incertidumbre, en el mejor de los casos la cuantifican. 

El p-value de la prueba de hipótesis depende de dos valores: el coeficiente y el error. Un p-value puede ser bajo --y, por lo tanto, el coeficiente estadísticamente significativo-- porque es muy lejano a 0 y tiene un error relativamente bajo. O ser muy cercano a 0, pero al tener un error muy bajo ser significativamente distinto. Vale la pena revisar los coeficientes y el error. Quizás un coeficiente sea significativo por tener un error muy pequeño, pero sigue siendo cercano a cero: su efecto es distinguible, pero muy pequeño. 

Consideremos al Modelo 4 y el coeficiente 0.0006491 para la variable POmenor5000. El p-value para ese coeficiente es 0.00264, sería razonable rechazar la hipótesis de nulidad y concluir que es diferente de 0. En este caso diríamos que la ruralidad tiene un efecto sobre la probabilidad de presidenta. Sin embargo ¿cuán tangible es ese efecto? En mi opinión, muy poco. La razón de probabilidad presidenta es 1.000649, es decir,  por cada incremento de un 1% de población en localidades con menos de 5000 habitantes aumenta un 0.0006491 la razón de probabilidad de presidenta. ¿Cuanto aumentaría si, digamos, nos pasamos de 0% de población en localidades menores a un 50%? Podemos obtener este número elevando el exponencial de $\beta$ al porcentaje que nos interesa. En este caso $1.000649^{50}=1.032987$. Es decir, pasando del 0 al 50% de población en localidades con menos de 5000 habitantes la probabilidad de presidenta aumenta un 3.2%. Dependerá de nuestra hipótesis sustantiva determinar si es un cambio importante o no. A mí me sabe a poco: la ruralidad tiene un efecto significativo, pero es muy bajo. No sería sorprendente que replicando estos datos para otro ciclo electoral esta pendiente desaparezca o cambie de signo. Podría ser, perfectamente, *ruido*.  

Consideremos algunas posibles interpretaciones erroneas de un p-value, es decir, que *no* es un p-value. 

- *No* es una magnitud que nos diga algo sobre la relación entre $x$ y $y$. Eso nos lo indica el coeficiente.  

- Un p-value bajo *no* significa que el coeficiente que estimó el modelo es el verdadero coeficiente. Solamente que podemos rechazar razonablemente la hipótesis  de que está en una distribución centrada en 0. ¡El verdadero coeficiente podría ser todavía más alto!

- *No* es la prueba definitiva de que nuestro coeficiente es diferente de 0. Las distribuciones de probabilidad son asintóticas, así que aún con un p-value extremadamente bajo sigue existiendo una probabilidad mayor que cero de que el verdadero coeficiente sea... 0. 

- *No* indica la cantidad de veces que debemos repetir el experimento --en este caso, modelar y obtener coeficientes para datos similares-- hasta obtener un error. Un p-value de 0.05 *no* puede interpretarse sostiendo que cada 100 modelos sólo 5 reportarán un falso positivo: aceptar que el coeficiente es diferente de 0 cuando no lo es. 

- Un p-value *no* estima la probabilidad de que la hipótesis estadística $H_1$ sea verdadera dados las datos. Hace todo lo contrario, estima la probabilidad de nuestros de datos dado $H_0$. 

#Anexo III. Tipos de variables independiente y modelo lineal apropiado. 

Variable dependiente | Definición | Ejemplo     | Tipo de modelo | Función en R
-----------|------------------|-----------------|-------------|----------
Continua             | Dentro de un rango, puede adquirir infinitos valores numéricos | Ingreso en pesos MN | Lineal con mínimos cuadrados ordinarios | `lm()`
Categórica dicotómica | Restringida a dos valores no ordenados | Sexo, Rural/urbano, Votó/No votó | logit | `glm(family=binomial())`
Categórica politómica | Más de dos categorías no ordenadas | Género, partido político, Grado de Marginación | `multinom()`
Conteo                | Conteo de eventos cuyo universo de probabilidad no es conocido^[Para los modelos logit podemos convertir a los conteos en probabilidades, ya que conocemos la n, el total de eventos.] | Denuncias por violencia de género | Lineal de Poisson | `glm(family=log())`
Proporción | y=0 y y=1 son proporciones que suman 1 | Composición parlamentaria: hombres y mujeres | Regresión beta | `betareg()`  
